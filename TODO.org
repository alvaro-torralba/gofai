* Alvaro:
** Curation of good/bad actions, run LAMA and check that all instances are still solved? or run an SMAC process which uses as many rules as possible while ensuring that all problems are solved
** Incremental learning: First learn good/bad actions, then take them into  account when training models
** Check that SMAC of bad rules works on freecell (right now, the bad rules do not work on p20, because they prune too aggresively)
** Combine cost and unit-cost good operators?

* Fix
** TODO Make sure that instance_features are defined for all features!
** [#A] Set time limits for everything
** ValueError(ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1
** plan partial grounding is crashing (when instances are not solved)
** Aleph not and equal do not work
**  File "/home/alvaro/planners/learning-ipc/data-search-floortile/runs-lama-exp/runs-00001-00100/00006/../../goodops-parser.py", line 26, in main FileNotFoundError: [Errno 2] No such file or directory: 'good_operators'

** /home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.


** Traceback (most recent call last):
  File "/home/alvaro/planners/learning-ipc/./learn.py", line 235, in <module>
    main()
  File "/home/alvaro/planners/learning-ipc/./learn.py", line 199, in main
    run_smac_partial_grounding(f'{TRAINING_DIR}', f'{TRAINING_DIR}/smac-partial-grounding', args.domain, BENCHMARKS_DIR, SMAC_INSTANCES,
  File "/home/alvaro/planners/learning-ipc/./training/optimize_smac.py", line 190, in run_smac_partial_grounding
    incumbent_config = smac.optimize()
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/facade/abstract_facade.py", line 289, in optimize
    incumbents = self._optimizer.optimize()
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/main/smbo.py", line 279, in optimize
    trial_info = self.ask()
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/main/smbo.py", line 151, in ask
    trial_info = next(self._trial_generator)
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/intensifier/intensifier.py", line 222, in __iter__
    config = next(self.config_generator)
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/main/config_selector.py", line 171, in __iter__
    X, Y, X_configurations = self._collect_data()
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/main/config_selector.py", line 280, in _collect_data
    X, Y = self._runhistory_encoder.transform(budget_subset=[b])
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/runhistory/encoder/abstract_encoder.py", line 265, in transform
    X, Y = self._build_matrix(trials=considered_trials, store_statistics=True)
  File "/home/alvaro/anaconda3/envs/SMAC/lib/python3.10/site-packages/smac/runhistory/encoder/encoder.py", line 44, in _build_matrix
    X[row, :] = np.hstack((conf_vector, feats))
ValueError: could not broadcast input array from shape (29,) into shape (31,)


** Traceback (most recent call last):
  File "/home/alvaro/planners/learning-ipc/./learn.py", line 235, in <module>
    main()
  File "/home/alvaro/planners/learning-ipc/./learn.py", line 192, in main
    run_step_partial_grounding_rules(REPO_LEARNING, training_data_set, f'{TRAINING_DIR}/partial-grounding-sklearn', args.domain)
  File "/home/alvaro/planners/learning-ipc/./training/partial_grounding_rules.py", line 33, in run_step_partial_grounding_rules
    useful_rules_files = [f for f in os.listdir(f'{WORKING_DIR}/training-data-good-operators-exhaustive-1k-filtered') if f.startswith('useful_rules')]
FileNotFoundError: [Errno 2] No such file or directory: 'learn-test/rovers/partial-grounding-sklearn/training-data-good-operators-exhaustive-1k-filtered'


** In rovers: 2023-04-26 08:57:22,058 INFO     filter-rules wall-clock time: 300.09s
2023-04-26 08:57:22,058 INFO     filter-rules wall-clock time: 300.09s
2023-04-26 08:57:22,058 INFO     filter-rules exit code: -24
2023-04-26 08:57:22,058 INFO     filter-rules exit code: -24


* Features
** [#A] Stone Soup
** [#B] Add BadPruning rules
** [#B] Add features from relaxed plans
** Do not learn anything for schemas having less than X examples on the training instances. Treat them as good operators (fully ground them). The assumption is that grounding is not a problem at all for those operators.

** [#C] Allow SMAC to tune stopping condition -> how? Use stopping condition based percentage of operators + X%, Does it make sense to do a stopping condition based on the action schema?

** [#B] Weighted round robin

** Run planners in parallel on the plan script

* Nice to have
** Fix numpy seed in learning scripts (via parameter)
** Virtual environment :)
** Open more parameters for sklearn
** Print warnings to std error (use some kind of logging?)
** Compress lab files? -> all_operators could be compressed and output could be removed
