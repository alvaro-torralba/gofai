* Daniel:
** Implement good/bad actions queue as part of the flexible queue


* Alvaro:
** Configure Aleph good/bad actions properly -> and parse good actions correctly
** Curation of good/bad actions, run LAMA and check that all instances are still solved? or run an SMAC process which uses as many rules as possible while ensuring that all problems are solved
** Use cost good operators as well
** Configure aleph to learn multiple models

** Incremental learning: First learn good/bad actions, then take them into  account when training models


* Fix
** [#A] Set time limits for everything
** Bad rules do not learn even the basic never paint down in floortile
** ValueError(ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1
** plan partial grounding is crashing (when instances are not solved)


** Bad rules in freecell colfromfreecell (?arg0, ?arg1, ?arg2, ?arg3) :- True. -> format not suported

** parse aleph theory -> need to add some equal constraints

** Aleph not and equal do not work


* Features
** [#A] Stone Soup
** [#B] Add BadPruning rules
** [#B] Add features from relaxed plans
** [#C] Do not learn anything for schemas having less than X examples on the training instances. Treat them as good operators (fully ground them). The assumption is that grounding is not a problem at all for those operators.

** [#C] Allow SMAC to tune stopping condition -> how? Use stopping condition based percentage of operators + X%, Does it make sense to do a stopping condition based on the action schema?

* Nice to have
** Fix numpy seed in learning scripts (via parameter)
** Virtual environment :)
** Open more parameters for sklearn
** Print warnings to std error (use some kind of logging?)
** Compress lab files? -> all_operators could be compressed and output could be removed
